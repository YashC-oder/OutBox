{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073de99d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 3.566688,
     "end_time": "2024-08-08T06:38:45.501506",
     "exception": false,
     "start_time": "2024-08-08T06:38:41.934818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install all necessary libraries and packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing and text handling\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63e60b0",
   "metadata": {
    "papermill": {
     "duration": 0.204458,
     "end_time": "2024-08-08T06:38:45.736881",
     "exception": false,
     "start_time": "2024-08-08T06:38:45.532423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you for reaching out! Your software solu...</td>\n",
       "      <td>Interested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi Sarah, I've booked our meeting for Thursday...</td>\n",
       "      <td>Meeting Booked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks for your email, but we're not intereste...</td>\n",
       "      <td>Not Interested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONGRATULATIONS! You've won $10,000! Click her...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am currently out of the office until March 1...</td>\n",
       "      <td>Out of Office</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Email Content           Label\n",
       "0  Thank you for reaching out! Your software solu...      Interested\n",
       "1  Hi Sarah, I've booked our meeting for Thursday...  Meeting Booked\n",
       "2  Thanks for your email, but we're not intereste...  Not Interested\n",
       "3  CONGRATULATIONS! You've won $10,000! Click her...            Spam\n",
       "4  I am currently out of the office until March 1...   Out of Office"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the dataset\n",
    "df= pd.read_csv('emails.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18283f",
   "metadata": {
    "papermill": {
     "duration": 0.010424,
     "end_time": "2024-08-08T06:38:45.759105",
     "exception": false,
     "start_time": "2024-08-08T06:38:45.748681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be87f863",
   "metadata": {
    "papermill": {
     "duration": 0.021832,
     "end_time": "2024-08-08T06:38:45.791674",
     "exception": false,
     "start_time": "2024-08-08T06:38:45.769842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec8c99a",
   "metadata": {
    "papermill": {
     "duration": 0.070455,
     "end_time": "2024-08-08T06:38:45.872933",
     "exception": false,
     "start_time": "2024-08-08T06:38:45.802478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Content    0\n",
      "Label            0\n",
      "dtype: int64\n",
      "Email Content    0\n",
      "Label            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values and drop them\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna()\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c87e6c9",
   "metadata": {
    "papermill": {
     "duration": 0.035042,
     "end_time": "2024-08-08T06:39:27.825073",
     "exception": false,
     "start_time": "2024-08-08T06:39:27.790031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TF-IDF Vectorization\n",
    "In the realm of Natural Language Processing (NLP), transforming text into numerical representations is essential for various tasks. TF-IDF vectorization stands out as a powerful technique for this purpose. \n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) vectorization is a method to represent text documents as numerical vectors. It measures the importance of a term within a document relative to the entire corpus. Let's break it down with a step-by-step example:\n",
    "\n",
    "## Example Corpus:\n",
    "Consider a small corpus with three documents:\n",
    "\n",
    "* Document 1: \"I love eating apples.\"\n",
    "* Document 2: \"Apples are delicious fruits.\"\n",
    "* Document 3: \"Bananas and oranges are also tasty.\"\n",
    "\n",
    "### Step 1: Calculate Term Frequency (TF)\n",
    "Term Frequency (TF) measures how often a term appears in a document relative to the total number of terms in that document.\n",
    "\n",
    "$$ \\text{TF} = \\frac{\\text{Frequency of the word in the sentence}}{\\text{Total number of words in the sentence}} $$\n",
    "\n",
    "For instance, let's calculate TF for the term \"apples\" in Document 1:\n",
    "\n",
    "* Number of times \"apples\" appears in Document 1 = 1\n",
    "* Total number of terms in Document 1 (excluding stop words) = 4\n",
    "* TF(\"apples\", Document 1) = 1 / 4 = 0.25\n",
    "\n",
    "Similarly, compute TF for all terms in each document.\n",
    "\n",
    "### Step 2: Calculate Inverse Document Frequency (IDF)\n",
    "Inverse Document Frequency (IDF) measures the rarity of a term across the entire corpus. It is calculated as the logarithm of the ratio of the total number of documents to the number of documents containing the term.\n",
    "\n",
    "$$ \\text{IDF} = \\frac{\\text{Total number of sentences (documents)}}{\\text{Number of sentences (documents) containing the word}} $$\n",
    "\n",
    "For example, let's calculate IDF for the term \"apples\":\n",
    "\n",
    "* Total number of documents in the corpus = 3\n",
    "* Number of documents containing the term \"apples\" = 2\n",
    "* IDF(\"apples\") = log(3 / 2) ≈ 0.176\n",
    "\n",
    "Calculate IDF for all terms in the corpus.\n",
    "\n",
    "### Step 3: Compute TF-IDF\n",
    "TF-IDF is obtained by multiplying TF by IDF for each term in each document.\n",
    "\n",
    "For \"apples\" in Document 1:\n",
    "\n",
    "* TF-IDF(\"apples\", Document 1) = TF(\"apples\", Document 1) * IDF(\"apples\") = 0.25 * 0.176 ≈ 0.044\n",
    "\n",
    "Similarly, calculate TF-IDF for all terms in each document.\n",
    "\n",
    "Each row represents a term, and each column represents a document. The values are the TF-IDF scores for each term in each document.\n",
    "\n",
    "Document 1 can be represented as [0.044,0,0,0.176,0,0.176,0,0,0]\n",
    "\n",
    "## Advantages of TF-IDF:\n",
    "1. Term Importance: TF-IDF emphasizes terms that are both frequent in a document and rare across the corpus, highlighting their significance in representing the content.\n",
    "2. Versatility: TF-IDF can be applied to various NLP tasks such as document classification, information retrieval, and keyword extraction, making it a versatile technique.\n",
    "3. Language Independence: TF-IDF does not rely on linguistic rules or language-specific features, making it applicable across different languages and domains.\n",
    "4. Simple Calculation: TF-IDF scores are straightforward to compute, involving basic arithmetic operations (TF and IDF calculations) applied to each term in each document.\n",
    "\n",
    "## Disadvantages of TF-IDF:\n",
    "1. Sparse Representation: TF-IDF matrices tend to be sparse, especially in large corpora with many unique terms, which can lead to storage and computational overhead.\n",
    "2. Lack of Semantic Understanding: TF-IDF does not consider the semantic relationships between terms, potentially leading to limitations in understanding context and meaning.\n",
    "3. Sensitivity to Vocabulary: TF-IDF is sensitive to the choice of vocabulary and may not perform well with out-of-vocabulary terms or rare words.\n",
    "4. Normalization Issues: TF-IDF scores may need to be normalized to account for document length variations, which can impact the effectiveness of the technique.\n",
    "\n",
    "## Applications of TF-IDF Vectorization\n",
    "TF-IDF vectorization finds extensive applications across various NLP tasks:\n",
    "1. **Document Classification**: TF-IDF vectors serve as features for training classifiers to categorize documents into predefined classes.\n",
    "2. **Information Retrieval**: Search engines utilize TF-IDF to rank documents based on their relevance to user queries.\n",
    "3. **Keyword Extraction**: TF-IDF aids in identifying important keywords within documents for summarization and content analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ed73d4",
   "metadata": {
    "papermill": {
     "duration": 0.705102,
     "end_time": "2024-08-08T06:39:28.565161",
     "exception": false,
     "start_time": "2024-08-08T06:39:27.860059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(df['Email Content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a58abd",
   "metadata": {
    "papermill": {
     "duration": 0.035192,
     "end_time": "2024-08-08T06:39:28.636463",
     "exception": false,
     "start_time": "2024-08-08T06:39:28.601271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train ~ Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1090a0",
   "metadata": {
    "papermill": {
     "duration": 0.056152,
     "end_time": "2024-08-08T06:39:28.727896",
     "exception": false,
     "start_time": "2024-08-08T06:39:28.671744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets for the Logistic Regression model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_vectors, df['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab798ed6",
   "metadata": {
    "papermill": {
     "duration": 0.036942,
     "end_time": "2024-08-08T06:39:28.800419",
     "exception": false,
     "start_time": "2024-08-08T06:39:28.763477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Machine Learning Models\n",
    "We will use the Logistic Regression, Support Vector Machine, Random Forest Classifier, Gradient Boosting  Classifier for sentiment analysis of the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ac80d49",
   "metadata": {
    "papermill": {
     "duration": 0.233255,
     "end_time": "2024-08-08T06:39:29.070233",
     "exception": false,
     "start_time": "2024-08-08T06:39:28.836978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing & calling Machine learning models\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b9525a4",
   "metadata": {
    "papermill": {
     "duration": 555.682248,
     "end_time": "2024-08-08T06:48:44.789391",
     "exception": false,
     "start_time": "2024-08-08T06:39:29.107143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "Accuracy Score: 0.7272727272727273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "accuracy_scores = accuracy_score(y_test,y_pred)\n",
    "print(lr_model)\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_pred)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50aa566",
   "metadata": {
    "papermill": {
     "duration": 0.037619,
     "end_time": "2024-08-08T06:49:02.703543",
     "exception": false,
     "start_time": "2024-08-08T06:49:02.665924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classification Report\n",
    "In the classification report, we can see things like accuracy, which tells us overall how often our model is correct. We also see precision, recall, and F1 Score, which give us insights into how well our model is doing at correctly identifying different classes . It's a performance evaluation metric commonly used in supervised machine learning tasks, especially for classification problems. Let me break it down for you:\n",
    "\n",
    "1. **Precision**: This metric measures how many of the positive predictions made by the model are actually correct. It's calculated as the ratio of true positives (correctly predicted positive samples) to the sum of true positives and false positives (incorrectly predicted positive samples).\n",
    "\n",
    "2. **Recall (Sensitivity)**: Recall tells us how many of the actual positive samples were correctly predicted by the model. It's calculated as the ratio of true positives to the sum of true positives and false negatives (actual positive samples missed by the model).\n",
    "\n",
    "3. **F1-Score**: The F1-score is the harmonic mean of precision and recall. It balances both metrics and provides a single value that represents the overall performance of the model.\n",
    "\n",
    "4. **Support**: Support indicates the number of samples in each class.\n",
    "\n",
    "We can generate a classification report using libraries like scikit-learn in Python using the `classification_report()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7e324f",
   "metadata": {
    "papermill": {
     "duration": 0.332466,
     "end_time": "2024-08-08T06:49:03.07428",
     "exception": false,
     "start_time": "2024-08-08T06:49:02.741814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Support Vector Classifier:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Interested       0.50      1.00      0.67         1\n",
      "Meeting Booked       1.00      0.67      0.80         3\n",
      "Not Interested       1.00      0.67      0.80         3\n",
      "          Spam       0.50      1.00      0.67         2\n",
      " Out of Office       1.00      0.50      0.67         2\n",
      "\n",
      "      accuracy                           0.73        11\n",
      "     macro avg       0.80      0.77      0.72        11\n",
      "  weighted avg       0.86      0.73      0.74        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Support Vector Classifier:\\n\", classification_report(y_test, y_pred, target_names=df['Label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a419bbd",
   "metadata": {
    "papermill": {
     "duration": 0.051618,
     "end_time": "2024-08-08T06:49:03.317022",
     "exception": false,
     "start_time": "2024-08-08T06:49:03.265404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meeting Booked']\n"
     ]
    }
   ],
   "source": [
    "text = [\"Hey team, just confirming our sync-up is at 4 PM tomorrow in Room 101.\"]\n",
    "category = lr_model.predict(tfidf_vectorizer.transform(text))\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "976c9544",
   "metadata": {
    "papermill": {
     "duration": 0.051622,
     "end_time": "2024-08-08T06:49:03.407306",
     "exception": false,
     "start_time": "2024-08-08T06:49:03.355684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Out of Office']\n"
     ]
    }
   ],
   "source": [
    "text = [\"I'm out of the office for the week and will respond upon my return.\"]\n",
    "category = lr_model.predict(tfidf_vectorizer.transform(text))\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20eef33e-c9d7-4e4b-9541-5dce047746f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(lr_model, open('models/email_categoriser.pkl', 'wb'))\n",
    "pickle.dump(tfidf_vectorizer, open('models/tfidf_vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227dfc0-451e-45cc-a3a6-7f1a7b29d21f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2066095,
     "sourceId": 3428111,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 625.63968,
   "end_time": "2024-08-08T06:49:04.348068",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-08T06:38:38.708388",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
